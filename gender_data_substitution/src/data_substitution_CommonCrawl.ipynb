{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hupu3S2OqAnZ"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX34WKTEqKrf"
      },
      "source": [
        "**Mount on drive** (if run on colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrbWvsSNo-xa",
        "outputId": "e9da32fd-4929-499c-d339-2284ac16f4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/GenderBiasFewShotText\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount= True)\n",
        "Folder_name = 'GenderBiasFewShotText'\n",
        "assert Folder_name is not None, \"[1] Enter the folder name\"\n",
        "import sys \n",
        "sys.path.append('content/drive/MyDrive/{}'.format(Folder_name))\n",
        "%cd drive/MyDrive/$Folder_name/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooz9AN5Ss7xF",
        "outputId": "6f85ed3f-58f3-49f2-a223-fd1993ba5925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GenderBiasFewShotText/gender_data_substitution/src\n"
          ]
        }
      ],
      "source": [
        "#execute this cell only if you run it colab\n",
        "BASE_PATH = 'gender_data_substitution/src'\n",
        "%cd {BASE_PATH}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbOTogQ6qMwG"
      },
      "source": [
        "**Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YlNZzKZ-LHE",
        "outputId": "f7955f5c-d1f3-444f-df05-93ca45c41140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Collecting c\n",
            "  Downloading c-0.1.0-py3-none-any.whl (13 kB)\n",
            "Collecting arrow==0.12.1\n",
            "  Downloading arrow-0.12.1.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting click==6.7\n",
            "  Downloading click-6.7-py2.py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting tabulate==0.8.2\n",
            "  Downloading tabulate-0.8.2.tar.gz (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.0\n",
            "  Downloading matplotlib-2.2.0.tar.gz (37.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting ipython==7.2.0\n",
            "  Downloading ipython-7.2.0-py3-none-any.whl (765 kB)\n",
            "\u001b[K     |████████████████████████████████| 765 kB 30.7 MB/s \n",
            "\u001b[?25hCollecting scipy==1.0.0\n",
            "  Downloading scipy-1.0.0.tar.gz (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting pandas==0.22.0\n",
            "  Downloading pandas-0.22.0.tar.gz (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 9.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/08/01/803834bc8a4e708aedebb133095a88a4dad9f45bbaf5ad777d2bea543c7e/pandas-0.22.0.tar.gz#sha256=44a94091dd71f05922eec661638ec1a35f26d573c119aa2fad964f10a2880e6c (from https://pypi.org/simple/pandas/). Command errored out with exit status 1: /usr/bin/python3 /tmp/pip-standalone-pip-5zrocgtv/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-9dzwcmgp/overlay --no-warn-script-location -v --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- wheel setuptools Cython 'numpy==1.9.3; python_version=='\"'\"'3.5'\"'\"'' 'numpy==1.12.1; python_version=='\"'\"'3.6'\"'\"'' 'numpy==1.13.1; python_version>='\"'\"'3.7'\"'\"'' Check the logs for full command output.\u001b[0m\n",
            "Collecting c\n",
            "  Downloading c-0.0.6-py3-none-any.whl (13 kB)\n",
            "  Downloading c-0.0.5-py3-none-any.whl (12 kB)\n",
            "  Downloading c-0.0.4-py3-none-any.whl (12 kB)\n",
            "  Downloading c-0.0.3-py3-none-any.whl (13 kB)\n",
            "  Downloading c-0.0.2-py3-none-any.whl (12 kB)\n",
            "Collecting pyparsing==2.2.0\n",
            "  Downloading pyparsing-2.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.7.0\n",
            "  Downloading python_dateutil-2.7.0-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 38.0 MB/s \n",
            "\u001b[?25hCollecting pytz==2018.3\n",
            "  Downloading pytz-2018.3-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting c\n",
            "  Downloading c-0.0.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: c\n",
            "Successfully installed c-0.0.1\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!pip install c\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-HgM3b0qPQq"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-3TbIB2po3iY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import spacy\n",
        "from operator import itemgetter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne4hBYtoqFI5"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fjK_hxlq-Q_"
      },
      "source": [
        "**remove duplicates from the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "a4h2aKNRo3iZ",
        "outputId": "8f1e5640-f4b7-4502-aaf1-aa93d21811e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data before dropping duplicates: 217197\n",
            "Length of data after dropping duplicates: 216943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          job gender                                        description\n",
              "0   professor      F   She is also a Ronald D. Asmus Policy Entrepre...\n",
              "1  accountant      M   He is a member of the AICPA and WICPA. Brent ...\n",
              "2   professor      M   Dr. Aster has held teaching and research posi...\n",
              "3   architect      M   He runs a boutique design studio attending cl...\n",
              "4   architect      M   He focuses on cloud security, identity and ac..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdc1d04f-fd4c-46b8-bc9a-c9537a0f1765\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job</th>\n",
              "      <th>gender</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>professor</td>\n",
              "      <td>F</td>\n",
              "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>accountant</td>\n",
              "      <td>M</td>\n",
              "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>professor</td>\n",
              "      <td>M</td>\n",
              "      <td>Dr. Aster has held teaching and research posi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>architect</td>\n",
              "      <td>M</td>\n",
              "      <td>He runs a boutique design studio attending cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>architect</td>\n",
              "      <td>M</td>\n",
              "      <td>He focuses on cloud security, identity and ac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdc1d04f-fd4c-46b8-bc9a-c9537a0f1765')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdc1d04f-fd4c-46b8-bc9a-c9537a0f1765 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdc1d04f-fd4c-46b8-bc9a-c9537a0f1765');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_path = '../data_utilities/'\n",
        "data = pd.read_csv(data_path+'CommonCrawl.csv', delimiter=',', encoding=\"utf-8\", skipinitialspace=True)\n",
        "print(f\"Length of data before dropping duplicates: {data.shape[0]}\")\n",
        "data = pd.DataFrame(data).drop_duplicates(subset=[\"job\", \"gender\", \"description\"])\n",
        "print(f\"Length of data after dropping duplicates: {data.shape[0]}\")\n",
        "data.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FByuH0cuo3ib"
      },
      "source": [
        "# Preprocessing: odd-ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5yywgQusJy"
      },
      "source": [
        "**Check how unbalanced the data is**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zg9pAQ1po3ic"
      },
      "outputs": [],
      "source": [
        "def odds_ratio(female_dict, male_dict, topk=1000, threshold=1):\n",
        "    #very_small_value = 0.00001\n",
        "    if len(female_dict.keys()) != len(male_dict.keys()):\n",
        "        raise Exception(\"The category for analyzing the male and female should be the same!\")\n",
        "    else:\n",
        "        odds_ratio = {}\n",
        "        total_num_female = sum(female_dict.values())\n",
        "        total_num_male = sum(male_dict.values())\n",
        "        for key in female_dict.keys():\n",
        "            male_num = male_dict[key]\n",
        "            female_num = female_dict[key]\n",
        "            non_female_num = total_num_female - female_num\n",
        "            non_male_num = total_num_male - male_num\n",
        "            if female_num >= threshold and male_num >= threshold:\n",
        "                # we only consider the events where there are at least {thresohld} occurences for both gender\n",
        "                odds_ratio[key] = round((male_num / female_num) / (non_male_num / non_female_num), 2)\n",
        "            else:\n",
        "                continue\n",
        "        return dict(sorted(odds_ratio.items(), key=itemgetter(1), reverse=True)[:topk]), dict(\n",
        "\n",
        "            sorted(odds_ratio.items(), key=itemgetter(1))[:topk])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHIIsr3No3id",
        "outputId": "888bec6b-ed06-480b-d9dc-312750631ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "female biased jobs: ['dietitian', 'interior_designer', 'model', 'nurse', 'paralegal', 'poet', 'psychologist', 'teacher', 'yoga_teacher']\n",
            "male biased jobs: ['accountant', 'architect', 'attorney', 'chiropractor', 'comedian', 'composer', 'dentist', 'dj', 'filmmaker', 'journalist', 'painter', 'pastor', 'personal_trainer', 'photographer', 'physician', 'professor', 'rapper', 'software_engineer', 'surgeon']\n"
          ]
        }
      ],
      "source": [
        "categories = data['job'].unique().tolist()\n",
        "counts = data.groupby(['job', 'gender']).size().unstack('gender').reset_index()\n",
        "counts['dominant'] = np.where(counts['F']>= counts['M'], 'F', 'M')\n",
        "counts['total'] = counts['F']+counts['M']\n",
        "\n",
        "female_biased_jobs=[]\n",
        "male_biased_jobs=[]\n",
        "\n",
        "for index, row in counts.iterrows():\n",
        "    if row[\"dominant\"]=='F':\n",
        "        female_biased_jobs.append(row[\"job\"])\n",
        "    else:\n",
        "        male_biased_jobs.append(row[\"job\"])\n",
        "\n",
        "print(f\"female biased jobs: {female_biased_jobs}\")\n",
        "print(f\"male biased jobs: {male_biased_jobs}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnc2uDDGo3id",
        "outputId": "0cec3e0d-192d-4382-be8c-fd0fb32bcc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Odd ratio for male dominant jobs: {'rapper': 9.51, 'surgeon': 5.63, 'software_engineer': 4.83, 'dj': 4.78, 'composer': 4.41, 'comedian': 3.18, 'architect': 2.97, 'pastor': 2.67, 'chiropractor': 2.19, 'filmmaker': 1.67, 'photographer': 1.61, 'dentist': 1.6, 'accountant': 1.49, 'attorney': 1.43, 'physician': 1.31, 'professor': 1.05, 'personal_trainer': 1.03, 'painter': 0.98, 'journalist': 0.84, 'poet': 0.83, 'teacher': 0.56, 'psychologist': 0.5, 'interior_designer': 0.2, 'model': 0.17, 'paralegal': 0.16, 'yoga_teacher': 0.15, 'dietitian': 0.07, 'nurse': 0.07}\n",
            "Odd ratio for female dominant jobs: {'dietitian': 0.07, 'nurse': 0.07, 'yoga_teacher': 0.15, 'paralegal': 0.16, 'model': 0.17, 'interior_designer': 0.2, 'psychologist': 0.5, 'teacher': 0.56, 'poet': 0.83, 'journalist': 0.84, 'painter': 0.98, 'personal_trainer': 1.03, 'professor': 1.05, 'physician': 1.31, 'attorney': 1.43, 'accountant': 1.49, 'dentist': 1.6, 'photographer': 1.61, 'filmmaker': 1.67, 'chiropractor': 2.19, 'pastor': 2.67, 'architect': 2.97, 'comedian': 3.18, 'composer': 4.41, 'dj': 4.78, 'software_engineer': 4.83, 'surgeon': 5.63, 'rapper': 9.51}\n"
          ]
        }
      ],
      "source": [
        "female_dict={}\n",
        "male_dict={}\n",
        "\n",
        "for index, row in counts.iterrows():\n",
        "    female_dict[row[\"job\"]]=row['F']\n",
        "    male_dict[row[\"job\"]]=row['M']\n",
        "    \n",
        "odds_m_c, odds_f_c = odds_ratio(female_dict, male_dict)\n",
        "\n",
        "print(f\"Odd ratio for male dominant jobs: {odds_m_c}\")\n",
        "print(f\"Odd ratio for female dominant jobs: {odds_f_c}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpBrBWbQvH90"
      },
      "source": [
        "**add biased classes (jobs) for both female and male in train, valid, and test split types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ghn1isFo3ie",
        "outputId": "d54ea88c-1adc-4506-967c-1ca8fa89a92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes for train split: ['paralegal' 'interior_designer' 'dietitian' 'composer'\n",
            " 'software_engineer' 'attorney' 'surgeon' 'physician' 'personal_trainer'\n",
            " 'chiropractor']\n",
            "Classes for valid split: ['nurse' 'poet' 'yoga_teacher' 'accountant' 'comedian' 'pastor'\n",
            " 'architect' 'rapper' 'dentist']\n",
            "Classes for test split: ['teacher' 'psychologist' 'model' 'filmmaker' 'professor' 'painter'\n",
            " 'journalist' 'photographer' 'dj']\n"
          ]
        }
      ],
      "source": [
        "#make sure to have biased jobs in train, valid, and test part\n",
        "np.random.shuffle(female_biased_jobs)\n",
        "np.random.shuffle(male_biased_jobs)\n",
        "female_occupations_split = np.array_split(female_biased_jobs, 3)\n",
        "male_occupations_split = np.array_split(male_biased_jobs, 3)\n",
        "\n",
        "train_occupations=np.concatenate((female_occupations_split[0], male_occupations_split[0]))\n",
        "valid_occupations=np.concatenate((female_occupations_split[1], male_occupations_split[1]))\n",
        "test_occupations=np.concatenate((female_occupations_split[2], male_occupations_split[2]))\n",
        "\n",
        "print(f\"Classes for train split: {train_occupations}\")\n",
        "print(f\"Classes for valid split: {valid_occupations}\")\n",
        "print(f\"Classes for test split: {test_occupations}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs_p-0Hho3if"
      },
      "source": [
        "# Flipping Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbPnwEEv-Zf"
      },
      "source": [
        "**In this section, the goal is to generate: gender flipped, neutral, pro-stereotype, anti-stereotype, and balanced datasets from the original dataset. For more information on how to create these datasets, please refer to the report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g-08Pg62o3ig"
      },
      "outputs": [],
      "source": [
        "nlp=spacy.load('en_core_web_sm')\n",
        "import sys\n",
        "\n",
        "from substitutor import Substitutor\n",
        "from substitutor import load_json_pairs\n",
        "\n",
        "gender_pairs = load_json_pairs(f'{data_path}/gender_pairs.json')\n",
        "neutral_pairs = load_json_pairs(f'{data_path}/neutral_pairs.json')\n",
        "full_names = json.loads(open(f'{data_path}/gender_names.json', \"rb\").readlines()[0])\n",
        "\n",
        "# Initialise a substitutor with a list of pairs of gendered words (and optionally names)\n",
        "substitutor = Substitutor(gender_pairs, full_names, neutral_pairs)\n",
        "# Example text which requires NER and POS information to properly invert\n",
        "def gender_flip(text):\n",
        "    flipped = substitutor.invert_text_gender(text)\n",
        "    return flipped\n",
        "\n",
        "def neutral_flip(text):\n",
        "    flipped = substitutor.invert_text_neutral(text)\n",
        "    return flipped\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92vD_QyezhUI"
      },
      "source": [
        "**Example on how to flip a text into opposite gender and gender free (neutral)text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO1whfCjo3ig",
        "outputId": "c93f8fc9-098f-40d5-c965-15fd4b85a242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text: Mike is nice, Lynn and James are nice\"\n",
            "gender flipped text: Kenly is nice, Davyn and Hannia are nice\"\n",
            "gender free: E3 is nice, E2 and E1 are nice\"\n"
          ]
        }
      ],
      "source": [
        "text = 'Mike is nice, Lynn and James are nice\"'\n",
        "gender_flipped = gender_flip(text)\n",
        "gender_free = neutral_flip(text)\n",
        "print(f\"original text: {text}\")\n",
        "print(f\"gender flipped text: {gender_flipped}\")\n",
        "print(f\"gender free: {gender_free}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdPclvX20diB"
      },
      "source": [
        "**Generate the datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os36fmC0o3ik"
      },
      "outputs": [],
      "source": [
        "train=[]\n",
        "valid=[]\n",
        "test=[]\n",
        "samples=[]\n",
        "\n",
        "\n",
        "neutral_train=[]\n",
        "neutral_valid=[]\n",
        "neutral_samples=[]\n",
        "\n",
        "#gf for gender flipped\n",
        "\n",
        "gf_train=[]\n",
        "gf_valid=[]\n",
        "gf_samples=[]\n",
        "\n",
        "\n",
        "pro_stereo_train=[]\n",
        "pro_stereo_valid=[]\n",
        "pro_stereo_samples=[]\n",
        "\n",
        "#gf for gender flipped\n",
        "\n",
        "anti_stereo_train=[]\n",
        "anti_stereo_valid=[]\n",
        "anti_stereo_samples=[]\n",
        "\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    samples.append(row['description'])\n",
        "    sen=gender_flip(row['description']) \n",
        "    gf_samples.append(sen)\n",
        "    sen_neutral=neutral_flip(row['description']) \n",
        "    neutral_samples.append(sen_neutral)\n",
        "    \n",
        "    if row['job'] in train_occupations:\n",
        "        train.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "        gf_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "        neutral_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen_neutral})\n",
        "        \n",
        "        if row['job'] in female_biased_jobs and row['gender']=='F':\n",
        "            pro_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "        \n",
        "            anti_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            anti_stereo_samples.append(sen)\n",
        "            \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='M':\n",
        "            pro_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "        \n",
        "            anti_stereo_train.append({'label':row['job'], 'gender':row['gender'],  'sentence': sen})\n",
        "            anti_stereo_samples.append(sen)\n",
        "        \n",
        "        elif row['job'] in female_biased_jobs and row['gender']=='M':\n",
        "        \n",
        "            pro_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            pro_stereo_samples.append(sen)\n",
        "        \n",
        "            anti_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            anti_stereo_samples.append(row['description'])\n",
        "        \n",
        "      \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='F':\n",
        "        \n",
        "            pro_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            pro_stereo_samples.append(sen)\n",
        "        \n",
        "            anti_stereo_train.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            anti_stereo_samples.append(row['description'])\n",
        "                \n",
        "            \n",
        "            \n",
        "    elif row['job'] in valid_occupations:\n",
        "        valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "        gf_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence':sen})\n",
        "        neutral_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen_neutral})\n",
        "        \n",
        "        if row['job'] in female_biased_jobs and row['gender']=='F':\n",
        "            pro_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "        \n",
        "            anti_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            anti_stereo_samples.append(sen)\n",
        "            \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='M':\n",
        "            pro_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "        \n",
        "            anti_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            anti_stereo_samples.append(sen)\n",
        "        \n",
        "        elif row['job'] in female_biased_jobs and row['gender']=='M':\n",
        "        \n",
        "            pro_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            pro_stereo_samples.append(sen)\n",
        "        \n",
        "            anti_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            anti_stereo_samples.append(row['description'])\n",
        "        \n",
        "      \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='F':\n",
        "        \n",
        "            pro_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': sen})\n",
        "            pro_stereo_samples.append(sen)\n",
        "        \n",
        "            anti_stereo_valid.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "            anti_stereo_samples.append(row['description'])\n",
        "                \n",
        "        \n",
        "    else:\n",
        "        test.append({'label':row['job'], 'gender':row['gender'], 'sentence': row['description']})\n",
        "        \n",
        "        if row['job'] in female_biased_jobs and row['gender']=='F':\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "            anti_stereo_samples.append(sen)\n",
        "            \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='M':\n",
        "            pro_stereo_samples.append(row['description'])\n",
        "            anti_stereo_samples.append(sen)\n",
        "        \n",
        "        elif row['job'] in female_biased_jobs and row['gender']=='M':\n",
        "        \n",
        "            pro_stereo_samples.append(sen)\n",
        "            anti_stereo_samples.append(row['description'])\n",
        "        \n",
        "      \n",
        "        elif row['job'] in male_biased_jobs and row['gender']=='F':\n",
        "        \n",
        "            pro_stereo_samples.append(sen)\n",
        "        \n",
        "            anti_stereo_samples.append(row['description'])\n",
        "                \n",
        "\n",
        "\n",
        "train_samples, test_samples= train_test_split(samples, shuffle=False, test_size=0.30)\n",
        "\n",
        "gf_train_samples, gf_test_samples= train_test_split(gf_samples, shuffle=False, test_size=0.30)\n",
        "\n",
        "pro_stereo_train_samples, pro_stereo_test_samples= train_test_split(pro_stereo_samples, shuffle=False, test_size=0.30)\n",
        "\n",
        "anti_stereo_train_samples, anti_stereo_test_samples= train_test_split(anti_stereo_samples, shuffle=False, test_size=0.30)\n",
        "\n",
        "neutral_train_samples, neutral_test_samples= train_test_split(neutral_samples, shuffle=False, test_size=0.30)\n",
        "\n",
        "\n",
        "#balanced dataset\n",
        "balanced_train = np.concatenate([train, gf_train])\n",
        "balanced_valid = np.concatenate([valid, gf_valid])\n",
        "\n",
        "balanced_samples_train=np.concatenate((train_samples, gf_train_samples))\n",
        "balanced_samples_test= np.concatenate((test_samples, gf_test_samples))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--DsacXxJ_fn"
      },
      "outputs": [],
      "source": [
        "       \n",
        "#checking existing dirs\n",
        "\n",
        "output_directory = '../../data/CommonCrawl'\n",
        "\n",
        "if not os.path.exists(output_directory):  \n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "\n",
        "if not os.path.exists(f'{output_directory}/original'):\n",
        "  os.makedirs(f'{output_directory}/original')\n",
        "  os.makedirs(f'{output_directory}/original/full')\n",
        "    \n",
        "if not os.path.exists(f'{output_directory}/gender-swapped'):\n",
        "  os.makedirs(f'{output_directory}/gender-swapped')\n",
        "  os.makedirs(f'{output_directory}/gender-swapped/full')\n",
        "    \n",
        "if not os.path.exists(f'{output_directory}/balanced'):\n",
        "  os.makedirs(f'{output_directory}/balanced')\n",
        "  os.makedirs(f'{output_directory}/balanced/full')\n",
        "    \n",
        "if not os.path.exists(f'{output_directory}/pro-stereotype'):\n",
        "  os.makedirs(f'{output_directory}/pro-stereotype')\n",
        "  os.makedirs(f'{output_directory}/pro-stereotype/full')\n",
        "\n",
        "if not os.path.exists(f'{output_directory}/anti-stereotype'):\n",
        "  os.makedirs(f'{output_directory}/anti-stereotype')\n",
        "  os.makedirs(f'{output_directory}/anti-stereotype/full')\n",
        "\n",
        "if not os.path.exists(f'{output_directory}/neutral'):\n",
        "  os.makedirs(f'{output_directory}/neutral')\n",
        "  os.makedirs(f'{output_directory}/neutral/full')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "with open(f'{output_directory}/neutral/train.jsonl', 'w') as f:\n",
        "  for obj in neutral_train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/neutral/valid.jsonl', 'w') as f:\n",
        "  for obj in neutral_valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/neutral/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "\n",
        "with open(f'{output_directory}/neutral/full/full-train.txt','w') as f:\n",
        "  f.write('\\n'.join(neutral_train_samples))\n",
        "    \n",
        "    \n",
        "with open(f'{output_directory}/neutral/full/full-test.txt','w') as f:\n",
        "  f.write('\\n'.join(neutral_test_samples))\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "#pro-stereo\n",
        "\n",
        "with open(f'{output_directory}/pro-stereotype/train.jsonl', 'w') as f:\n",
        "  for obj in pro_stereo_train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/pro-stereotype/valid.jsonl', 'w') as f:\n",
        "  for obj in pro_stereo_valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/pro-stereotype/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "              \n",
        "with open(f'{output_directory}/pro-stereotype/full/full-train.txt','w') as f:\n",
        "    f.write('\\n'.join(pro_stereo_train_samples))\n",
        " \n",
        "    \n",
        "\n",
        "with open(f'{output_directory}/pro-stereotype/full/full-test.txt','w') as f:\n",
        "    f.write('\\n'.join(pro_stereo_test_samples))\n",
        "\n",
        "\n",
        "\n",
        "#anti-stereo \n",
        "\n",
        "with open(f'{output_directory}/anti-stereotype/train.jsonl', 'w') as f:\n",
        "  for obj in anti_stereo_train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/anti-stereotype/valid.jsonl', 'w') as f:\n",
        "  for obj in anti_stereo_valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "\n",
        "with open(f'{output_directory}/anti-stereotype/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "\n",
        "with open(f'{output_directory}/anti-stereotype/full/full-train.txt','w') as f:\n",
        "  f.write('\\n'.join(anti_stereo_train_samples))\n",
        "\n",
        "\n",
        "with open(f'{output_directory}/anti-stereotype/full/full-test.txt','w') as f:\n",
        "  f.write('\\n'.join(anti_stereo_test_samples))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "with open(f'{output_directory}/original/train.jsonl', 'w') as f:\n",
        "  for obj in train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/original/valid.jsonl', 'w') as f:\n",
        "  for obj in valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/original/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/original/full/full-train.txt','w') as f:\n",
        "    f.write('\\n'.join(train_samples))\n",
        "    \n",
        "    \n",
        "with open(f'{output_directory}/original/full/full-test.txt','w') as f:\n",
        "    f.write('\\n'.join(test_samples))\n",
        "    \n",
        "    \n",
        "# writing gender-swapped datasets \n",
        "\n",
        "with open(f'{output_directory}/gender-swapped/train.jsonl', 'w') as f:\n",
        "  #json.dump(gender_swapped_dataset, jsonfile)\n",
        "  for obj in gf_train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/gender-swapped/valid.jsonl', 'w') as f:\n",
        "  #json.dump(gender_swapped_dataset, jsonfile)\n",
        "  for obj in gf_valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "with open(f'{output_directory}/gender-swapped/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "\n",
        "                       \n",
        "# write full datasets  \n",
        "\n",
        "with open(f'{output_directory}/gender-swapped/full/full-train.txt','w') as f:\n",
        "  f.write('\\n'.join(gf_train_samples))\n",
        "\n",
        "with open(f'{output_directory}/gender-swapped/full/full-test.txt','w') as f:\n",
        "  f.write('\\n'.join(gf_test_samples))\n",
        " \n",
        "\n",
        "\n",
        "# writing balanceed datasets  \n",
        "        \n",
        "with open(f'{output_directory}/balanced/train.jsonl', 'w') as f:\n",
        "  for obj in balanced_train:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/balanced/valid.jsonl', 'w') as f:\n",
        "  for obj in balanced_valid:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "        \n",
        "with open(f'{output_directory}/balanced/test.jsonl', 'w') as f:\n",
        "  for obj in test:\n",
        "    f.write(json.dumps(obj) + '\\n')\n",
        "    \n",
        "with open(f'{output_directory}/balanced/full/full-train.txt','w') as f:\n",
        "  f.write('\\n'.join(balanced_train_samples))\n",
        "    \n",
        "with open(f'{output_directory}/balanced/full/full-test.txt','w') as f:\n",
        "  f.write('\\n'.join(balanced_test_samples))\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "generate_data_CommonCrawl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}